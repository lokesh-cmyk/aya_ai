/**
 * Text chunking utilities for KB document processing.
 *
 * Embeddings are generated by Pinecone's integrated model (llama-text-embed-v2),
 * so we only need to chunk text here â€” no OpenAI embedding calls needed.
 */

const CHUNK_SIZE = 1000;
const CHUNK_OVERLAP = 200;

export interface TextChunk {
  text: string;
  index: number;
}

export function chunkText(text: string): TextChunk[] {
  const words = text.split(/\s+/);
  const chunks: TextChunk[] = [];
  let index = 0;

  for (let i = 0; i < words.length; i += CHUNK_SIZE - CHUNK_OVERLAP) {
    const chunk = words.slice(i, i + CHUNK_SIZE).join(" ");
    if (chunk.trim()) {
      chunks.push({ text: chunk, index });
      index++;
    }
  }

  return chunks.length > 0 ? chunks : [{ text: text.trim(), index: 0 }];
}
